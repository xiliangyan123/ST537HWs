---
title: "ST537/437 HW3"
author: 
- Michael Yan 
date: "Date Submitted: 02/22/2020"
output:
  pdf_document:
    fig_caption: yes
    highlight: pygments
    keep_tex: yes
    number_sections: yes
    toc: yes
header-includes: 
  - \usepackage{float}
  - \usepackage{longtable}
---
\centering

\raggedright

\clearpage

\tableofcontents

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
library(GGally)
library(knitr)
library(tidyverse)
library(sem)
```

# Problem 1 - Harman23.cor Data 

```{r Q1}
#Question 1A). 
dat <- Harman23.cor$cov

#a). Provide a plot to visualize the 
corrpt <- ggcorr(dat, label = TRUE, label.size = 0, label_round = 2) %>% print()

# From the patterns we see in the correlation plot, we see that many of the variables are correlated with each other. There is a lot of multicollinearity. 

#b). Perform PCA on this data and retain the first two pcs. Report the loadings
pca1 <- prcomp(dat) %>% print()
round(pca1$rotation[, 1:2], 3)

#c). How much total variation is captured by each of the two first PCs? How much of the total variation is captured by the 2 PCs together? 

pca.sum <- summary(pca1)
pca.sum$importance[, c(1:2)]

# Total variation captured by each: PC1 - 85.28%, PC2 - 5.987%
# Total variation captured by both: PC1 + PC2 = 91.267%

#d). Interpret the first 2 PCs as best as you can:
# The first 2 pcs can be interpreted as the summaries of physical measurements on girls between ages of 7 and 17. For the first PC, we see that 

# for the first PC, we see that the height, armspan, and forearm explain most for our dependent variable, whereas the second PC, we see that the chest.width and the chest.girth explain most of the variation for our dependent variable. 
```

## Problem 1 Answers: 
#A). Please see above output for correlation matrix. For the patterns that we see in the correlation plot, we see that many variables are correlated with each other. For instance, we see patterns such as armspan and height being highly correlated with each other, which we will need to consider for when making inferences. 

#B). PCA Loadings - Please see the above output for the loadings and first 2 PCs

#C). The Total variation captured by the first PC is 85.28$\%$ and the total variation captured by the second PC is 5.987$\%$, The total Variation that is captured by the first two PCs is 91.267$\%$

#D). Interpretation of the 

```{r Q2}
library(sem)
library(corrplot)
library(psych)
library(GPArotation)
lt <- readMoments("EverittEx5.5.txt", diag = TRUE) %>% print()
R <- (lt + t(lt)) - diag(1, 6)
colnames(R) <- c("French", "English", "History", "Arithmetic", "Algebra", "Geometry")
rownames(R) <- c("French", "English", "History", "Arithmetic", "Algebra", "Geometry")
R

# Are two factors sufficient or Not?
fa.parallel(R, n.iter = 100, fm = "ml", fa = "fa")
fa.mle <- fa(R, nfactors = 2, rotate = "none", fm = "ml", n.obs = 220)
fa.varimax <- fa(R, nfactors = 2, rotate = "varimax", fm = "ml", n.obs = 220)
# Based on the parallel analysis, we notice that there is still a noticeable difference, when factors = 2.
# We find that number of factors = 2 may not be enough to fit the data. 

# Satisfaction of uniquenesses and communialities
# Loadings
loadings.n <- fa.mle$loadings
loadings.v <- fa.varimax$loadings
loadings <- cbind(loadings.n, loadings.v)
colnames(loadings) <- c("None F1","None F2", "Varimax F1", "Varimax F2" )
loadings

# Communialities 
comms.n<- rowSums(fa.mle$loadings^2) 
comms.v <- rowSums(fa.varimax$loadings^2)
comms <- cbind(comms.n, comms.v)
colnames(comms) <- c("None", "Varimax")
comms

# We originally used a two-factor model for our model fit. To determine if this model was a good fit for the data, the communialities for each variable should be close to 1. However, we see here that the communialities are not close to 1, and thus, we can argue that the communialities are not satisfactory. 

# For uniquenesses, we should expect that these values be small. We can calculate the uniquenesses by doing: uniquenesses = 1 - communialities. We see from our output that having communialities subtracted from 1 is quite large, around 50% +. Thus, uniquenesses are not satisfactory. 


# Interpretation of the factor loadings, exploring a few rotations if needed.

# Based on the factor loadings, it seems that factor 1 with no rotation and factor 1 with the varimax rotation are strong influences for the arithmetic and the alegebra variables. As for factor 2 with varimax rotation and without rotation, we find that those have a rather weaker influence on the geometry, algebra, and arithmetic variable. 


# Comment on whether factor scores can be computed here or not
par(mfrow = c(2,3))

fa.quartimax <- fa(R, nfactors = 2, n.obs = 220, fm = "ml", rotate = "quartimax")

fa.diagram(fa.mle, cut = 0.20, simple = FALSE, main = "no rotation")
fa.diagram(fa.varimax, cut = 0.20, simple = FALSE, main = "Varimax rotation")
fa.diagram(fa.quartimax, cut = 0.20, simple = FALSE, main = "Quartimax rotation")

# Based on the rotations, we find it difficult to interpret the fixed set of loadings. If we wish to predict and interpret for the factor scores, we would probably need more than 2 factors. 
```

```{r Q3}
#A). How many manifest variables are observed? How many common factors extracted?

# There are 8 manifest variables and 3 extracted common factors

#B). Create a table showing the communialities and uniquenesses for each manifest variable. 

f1.loads <- c(.665, 0, 0.798, .717, 0, 0, -.218, .810)
f2.loads <- c(-.354, .205, -.127, 0, .318, .831, .594, 0.00)
f3.loads <- c(0.167, .664, 0, -.121, .609, .367, .314, -.366)

factor.loads <- cbind(f1.loads, f2.loads, f3.loads)
comms.1 <- rowSums(factor.loads**2) %>% print()
uniqs.1 <- 1-comms.1 %>% print()

# C). Is the fitted model sufficient for the data? Explain your answer. 

# To determine this, we can look at the p-value given in the output. With a p-value of 0.0898, we can argue that a 3-factor model fits the data well, at the 0.05 level. However, this p-value does seem near the border, and we could possibly introduce a fourth factor as well. 

## To determine this, we will look at the uniquenesses, or the part of the variance(x_i) not captured by the common factors. We observed that these values range from 0.472005 to 0.825250. Ideally, we would like these values to be small, and based on this data, we conclude that the fitted model is likely not sufficient enough for the data.##

#D). What proportion of var(X_1) is captured/explained by only factor 1? By factor 1 and factor 2 together? 

# By factor 1: 
propX1.F1 <- f1.loads[1]**2 / comms.1[1]
propX1.F1

# By factors 1 and 2 together:
propX1X2.F1 <- (f1.loads[1]**2 + f2.loads[1]**2) / comms.1[1]
propX1X2.F1

#E). Which factor has the highest correlation (in absolute value) with X_7? Justify your answer by actually computing the correlation. 

# The highest correlation exists in factor 2 for X_7, which has a loadings value of 0.594. The loadings quantifies the strength of a linear relationship. 
hcX7 <- factor.loads[7,2]

# f). Estimate the correlation between X_1 and X_4
cov.X1X4 <- (factor.loads[1,1] * factor.loads[4,1] + (factor.loads[1,2]*factor.loads[4,2]) + (factor.loads[1,3]*factor.loads[4,3]))
sd.X1 <- sqrt(factor.loads[1] + uniqs.1[1]) 
sd.X4 <- sqrt(factor.loads[4] + uniqs.1[4]) 

corr.X1X4 <- (cov.X1X4/(sd.X1*sd.X4)) %>% print()
names(corr.X1X4) <- "Correlation"
corr.X1X4
```

```{r Q4}
lt1 <- readMoments("EverittEx7.1.txt", diag = TRUE)
R1 <- (lt1 + t(lt1)) - diag(1,9)

R2 <- R1[-9,-9]
R2

n = 123

# We want to fit a correlated 2-factor model in wich questions 1, 3, 4, and 8 are assumed to be indicators of the latent variable Doctor's Responsibility and questions 2, 5, 6, and 7 to be indicators of the latent variable Patient's Responsibility. Find a 95% confidence interval for the correlation between the two latent variables. 


```


```{r Q5}
#women's data
women <- read.table("T1-9.dat", header = FALSE, sep = "\t")

nm1 <- c("Country", "100m", "200m", "400m", "800m", "1500m", "3000m", "Marathon")
colnames(women) <- nm1
rownames(women) <- women[,1]
head(women)

#A). Perform a pca on the sample correlation matrix of the data. Interpret the first two PCs as best as you can. 
women.pca <- prcomp(women[,-1]) %>% print()
summary(women.pca)

#B). Can we rank the nations based on PC1 scores? Does this correspoind with your intuitive notion of athletic excellence for the various countries. Explain. 

#C). The times for "100m", "200m", "400m" were given in seconds, and the other 4 variables were recorded in minutes. Convert the data to speed (meters/sec), and then repeat parts A) and B). Does your interpretation of the first two PCs change? [Hint: Marathon is 42,195 meters long.]
```